{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n",
      "Data split done\n",
      "Data reshaping done\n",
      "Done zipping and converting\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 37.62 MiB (GPU 0; 11.91 GiB total capacity; 89.80 MiB already allocated; 38.06 MiB free; 2.20 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-08ef06578f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 37.62 MiB (GPU 0; 11.91 GiB total capacity; 89.80 MiB already allocated; 38.06 MiB free; 2.20 MiB cached)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math as m\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "'''\n",
    "Loading Data\n",
    "'''\n",
    "Y_file = np.load('/ssd1/pore_data/jeffY00_Y08_LBset&set1set2set3_MinIONNoise_LBNoise_EcoliNoise_classes_05142019.npy')\n",
    "X_file = np.load('/ssd1/pore_data/jeffY00_Y08_LBset&set1set2set3_MinIONNoise_LBNoise_EcoliNoise_raw20000_05142019.npy')\n",
    "print('Data loaded successfully')\n",
    "\n",
    "Y_file = Y_file.flatten()\n",
    "\n",
    "window_length = 19881\n",
    "X_file = X_file[:,:window_length]\n",
    "\n",
    "\n",
    "'''\n",
    "Train, test split\n",
    "'''\n",
    "X_train = X_file.reshape(\n",
    "        len(X_file), X_file.shape[1], 1)\n",
    "labels_train = Y_file\n",
    "\n",
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(\n",
    "        X_train, labels_train, stratify = labels_train, train_size = 0.8)\n",
    "\n",
    "X_vld, X_test, lab_vld, lab_test = train_test_split(X_vld, lab_vld, stratify = lab_vld)\n",
    "\n",
    "y_tr = lab_tr.astype(int)\n",
    "y_vld = lab_vld.astype(int)\n",
    "y_test = lab_test.astype(int)\n",
    "\n",
    "print('Data split done')\n",
    "\n",
    "'''\n",
    "If gpu is available we will use it\n",
    "'''\n",
    "use_cuda = True\n",
    "\n",
    "'''\n",
    "Reshaping data\n",
    "'''\n",
    "reshape = 141\n",
    "\n",
    "X_tr = X_tr.reshape(len(X_tr),1,reshape,reshape)\n",
    "X_vld = X_vld.reshape(len(X_vld),1,reshape,reshape)\n",
    "X_test = X_test.reshape(len(X_test),1,reshape,reshape)\n",
    "print('Data reshaping done')\n",
    "\n",
    "\n",
    "'''\n",
    "Zipping data together and storing in trainloader objects\n",
    "'''\n",
    "train_set = list(zip(X_tr, y_tr))\n",
    "val_set = list(zip(X_vld, y_vld))\n",
    "test_set = list(zip(X_test, y_test))\t\t\t\t\t\t\t\t  \n",
    "print('Done zipping and converting')\n",
    "\n",
    "'''\n",
    "Creating the neural net\n",
    "'''\n",
    "best_accuracy = -float('Inf')\n",
    "best_params = []\n",
    "\n",
    "batch_size = 30\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "\t\ttrain_set, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "vldloader = torch.utils.data.DataLoader(\n",
    "\t\tval_set, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "\t\ttest_set, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "\n",
    "lr = 0.001\n",
    "epochs = 250\n",
    "momentum = 0.7557312793639288\n",
    "\t\t\n",
    "O_1 = 17\n",
    "O_2 = 18\n",
    "O_3 = 32\n",
    "O_4 = 37\n",
    "\n",
    "K_1 = 3\n",
    "K_2 = 1\n",
    "K_3 = 4\n",
    "K_4 = 2\n",
    "\n",
    "KP_1 = 4\n",
    "KP_2 = 4\n",
    "KP_3 = 1\n",
    "KP_4 = 1\n",
    "\n",
    "conv_linear_out = int(m.floor((m.floor((m.floor((m.floor((m.floor((reshape - K_1 + 1)/KP_1) - \n",
    "\tK_2 + 1)/KP_2) - K_3 + 1)/KP_3) - K_4 + 1)/KP_4)**2)*O_4))\n",
    "\t\n",
    "FN_1 = 148\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\n",
    "\t\tsuper(CNN, self).__init__()\n",
    "\n",
    "\t\tself.conv1 = nn.Sequential(nn.Conv2d(1,O_1,K_1),nn.ReLU(), \n",
    "\t\t\t\t\t\t\t\t   nn.MaxPool2d(KP_1))\n",
    "\t\t#self.conv1_bn = nn.BatchNorm2d(O_1)\n",
    "\n",
    "\t\tself.conv2 = nn.Sequential(nn.Conv2d(O_1,O_2,K_2),nn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t   nn.MaxPool2d(KP_2))\n",
    "\t\t#self.conv2_bn = nn.BatchNorm2d(O_2)\n",
    "\n",
    "\t\tself.conv3 = nn.Sequential(nn.Conv2d(O_2,O_3,K_3),nn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t   nn.MaxPool2d(KP_3))\n",
    "\t\t#self.conv3_bn = nn.BatchNorm2d(O_3)\n",
    "\n",
    "\t\tself.conv4 = nn.Sequential(nn.Conv2d(O_3,O_4,K_4),nn.ReLU(),\n",
    "\t\t\t\t\t\t\t\t   nn.MaxPool2d(KP_4))\n",
    "\t\t#self.conv4_bn = nn.BatchNorm2d(O_4)\n",
    "\n",
    "\t\tself.fc1 = nn.Linear(conv_linear_out, FN_1, nn.Dropout(0.2))\n",
    "\t\t#self.fc1_bn = nn.BatchNorm1d(FN_1)\n",
    "\t\t\n",
    "\n",
    "\t\tself.fc2 = nn.Linear(FN_1, 10)\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t  x = x.float()\n",
    "\t  x = F.leaky_relu(self.conv1(x))\n",
    "\t  #x = F.relu(self.conv1_bn(x))\n",
    "\t  x = F.leaky_relu(self.conv2(x))\n",
    "\t  #x = F.relu(self.conv2_bn(x))\n",
    "\t  x = F.leaky_relu(self.conv3(x))\n",
    "\t  #x = F.relu(self.conv3_bn(x))\n",
    "\t  x = F.leaky_relu(self.conv4(x))\n",
    "\t  #x = F.relu(self.conv4_bn(x))\n",
    "\t  x = x.view(len(x), -1)\n",
    "\t  x = F.logsigmoid(self.fc1(x))\n",
    "\t  #x = F.relu(self.fc1_bn(x))\n",
    "\t  x = self.fc2(x)\n",
    "\t  return x\n",
    "    #?return F.log_softmax(x)\n",
    "\n",
    "net = CNN()\n",
    "\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "\tnet.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "for epoch in range(250):  # loop over the dataset multiple times\n",
    "\n",
    "\trunning_loss = 0.0\n",
    "\tfor i,data in enumerate(trainloader, 0):\n",
    "\t\tinputs,labels = data\n",
    "\t\tif use_cuda and torch.cuda.is_available():\n",
    "\t\t\tinputs = inputs.cuda()\n",
    "\t\t\tlabels = labels.cuda()\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\toutputs = net(inputs)\n",
    "\t\toutputs = outputs.to(dtype = torch.float64)\n",
    "\t\tlabels = labels.to(dtype = torch.long)\n",
    "\t\tloss = criterion(outputs, labels)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\tprint('Finished epoch number ' + str(epoch))\n",
    "\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor data in vldloader:\n",
    "\t\t\tinputs, labels = data\n",
    "\t\t\tinputs = inputs.cuda()\n",
    "\t\t\tlabels = labels.cuda()\n",
    "\t\t\toutputs = net(inputs)\n",
    "\t\t\t_, predicted = torch.max(outputs.data, 1)\n",
    "\t\t\ttotal += len(labels)\n",
    "\t\t\tcorrect += (predicted == labels).sum().item()\n",
    "\n",
    "\tprint('Accuracy of the network on the validation set: %d %%' \n",
    "\t% (100 * correct / total))\n",
    "    \n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "\tfor data in testloader:\n",
    "\t\tinputs, labels = data\n",
    "\t\tinputs = inputs.cuda()\n",
    "\t\tlabels = labels.cuda()\n",
    "\t\toutputs = net(inputs)\n",
    "\t\t_, predicted = torch.max(outputs.data, 1)\n",
    "\t\ttotal += len(labels)\n",
    "\t\tcorrect += (predicted == labels).sum().item()\n",
    "\n",
    "\tprint('Accuracy of the network on the test set: %d %%' \n",
    "\t% (100 * correct / total))\n",
    "\n",
    "text_file = open(\"/disk1/pore_data/jeff_saved/NTERs_trained_cnn_results_05152019.txt\", \"w\")\n",
    "text_file.write(\"Accuracy of the network on the test set: %d %%\" % (100 * correct / total))\n",
    "text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "'''\n",
    "Saving the trained net\n",
    "'''\n",
    "\t\n",
    "#torch.save(net, '/disk1/pore_data/jeff_saved/NTERs_trained_cnn_05152019.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
