{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:50:48.142298Z",
     "start_time": "2018-09-11T19:50:46.600135Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "alpha = list(string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the variables in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:50:48.373125Z",
     "start_time": "2018-09-11T19:50:48.366774Z"
    }
   },
   "outputs": [],
   "source": [
    "date = \"20190504\"\n",
    "f5_base_dir = \"/disk1/pore_data\"\n",
    "f5_dir = \"MinION_raw_data_%s\" % date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:50:48.923621Z",
     "start_time": "2018-09-11T19:50:48.916308Z"
    }
   },
   "outputs": [],
   "source": [
    "min_duration_obs = 10\n",
    "signal_threshold = 0.7\n",
    "open_pore_mean = 220.\n",
    "open_pore_stdv = 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:50:49.324113Z",
     "start_time": "2018-09-11T19:50:49.309081Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(os.path.join(f5_base_dir, f5_dir))\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:52:15.152875Z",
     "start_time": "2018-09-11T19:52:15.028228Z"
    }
   },
   "outputs": [],
   "source": [
    "for fname in os.listdir(f5_base_dir):\n",
    "    if date in fname and fname.endswith(\".fast5\"):\n",
    "        mv_cmd = \"\".join([\"mv \", os.path.join(f5_base_dir, fname), \" \", os.path.join(f5_base_dir, f5_dir)]) + \"/\"\n",
    "        print mv_cmd\n",
    "        !{mv_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for reading Google Drive spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:54:59.793555Z",
     "start_time": "2018-09-11T19:54:59.285574Z"
    }
   },
   "outputs": [],
   "source": [
    "def import_gdrive_sheet(gdrive_key, sheet_id):\n",
    "    run_spreadsheet = pd.read_csv(\"https://docs.google.com/spreadsheet/ccc?key=\" + \\\n",
    "                                  peptide_gdrive_key + \"&output=csv&gid=\" + sheet_id)\n",
    "    run_spreadsheet.Date = pd.to_datetime(run_spreadsheet.Date, format=\"%m_%d_%y\")\n",
    "    return run_spreadsheet\n",
    "\n",
    "peptide_gdrive_key = \"1CRnphJXZ4QZSg21-0SlcyUwO0H1nMGTfTjH_G7q9fJM\"\n",
    "sheet_id = \"1709785742\"\n",
    "\n",
    "run_spreadsheet = import_gdrive_sheet(peptide_gdrive_key, sheet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:55:00.334070Z",
     "start_time": "2018-09-11T19:55:00.264320Z"
    },
    "code_folding": [
     4,
     19,
     23
    ]
   },
   "outputs": [],
   "source": [
    "def get_run_info(run_spreadsheet, date_yyyymmdd, runs=None):\n",
    "    date = datetime.date(int(date_yyyymmdd[:4]), int(date_yyyymmdd[4:6]), int(date_yyyymmdd[6:]))\n",
    "    all_runs = run_spreadsheet[[\"Date\", \"File name\"]].drop_duplicates()\n",
    "    runs_on_date_ix = []\n",
    "    for i, run_date, run_fname in all_runs.itertuples():\n",
    "        if not isinstance(run_fname, str):\n",
    "            continue\n",
    "        fname_search = re.findall(r\"(\\d+)_(\\d+)_(\\d+)_(run_\\d+)\", run_fname)\n",
    "        if len(fname_search) == 0 or len(fname_search[0]) < 4:\n",
    "            continue\n",
    "        m, d, y, run = fname_search[0]\n",
    "        if len(y) == 2:\n",
    "            y = \"20\" + y\n",
    "        fname_date = datetime.date(int(y), int(m), int(d))\n",
    "        if fname_date == date:\n",
    "            runs_on_date_ix.append(i)\n",
    "    runs_on_date = all_runs.loc[runs_on_date_ix]\n",
    "    runs_on_date[\"Date\"] = date\n",
    "    \n",
    "    if runs is not None:\n",
    "        runs_on_date = runs_on_date[runs_on_date[\"File name\"].isin(runs)]\n",
    "    \n",
    "    runs_by_date = {}\n",
    "    for i in runs_on_date.index:\n",
    "        start_line = i\n",
    "        next_ix = list(all_runs.index).index(start_line) + 1\n",
    "        if next_ix >= len(all_runs.index):\n",
    "            end_line = run_spreadsheet.index[-1]\n",
    "        else:\n",
    "            end_line = list(all_runs.index)[next_ix] - 1\n",
    "        runs_by_date[runs_on_date.loc[i, \"File name\"]] = run_spreadsheet.loc[start_line:end_line, :]\n",
    "\n",
    "    formatted_coords = {}\n",
    "    for run, df in runs_by_date.iteritems():\n",
    "        formatted_coords[run] = []\n",
    "        # print df\n",
    "        for i, coords in enumerate(df.loc[:, [\"start (sec)\", \"end (sec)\"]].iterrows()):\n",
    "            letter = alpha[i]\n",
    "            if np.isnan(coords[1][0]):\n",
    "                continue\n",
    "            start = int(coords[1][0])\n",
    "            if np.isnan(coords[1][1]):\n",
    "                end = start + 100\n",
    "            else:\n",
    "                end = int(coords[1][1])\n",
    "            formatted_coords[run].append({\"name\": letter, \"start\": start, \"end\": end})\n",
    "            \n",
    "    return runs_by_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort runs by flow cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:56:00.138312Z",
     "start_time": "2018-09-11T19:56:00.108579Z"
    }
   },
   "outputs": [],
   "source": [
    "runs_by_date = get_run_info(run_spreadsheet, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_by_date_df = runs_by_date.values()\n",
    "flowcells = []\n",
    "for df in runs_by_date_df:\n",
    "    if df.iloc[0][\"Flow Cell\"] not in flowcells:\n",
    "         flowcells.append(df.iloc[0][\"Flow Cell\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:56:02.484984Z",
     "start_time": "2018-09-11T19:56:02.475509Z"
    }
   },
   "outputs": [],
   "source": [
    "all_f5_files = [x for x in os.listdir(os.path.join(f5_base_dir, f5_dir)) if x.endswith(\".fast5\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f5_files_by_flowcell = dict.fromkeys(flowcells)\n",
    "for flowcell in flowcells:\n",
    "    f5_files_by_flowcell[flowcell] = [f5 for f5 in all_f5_files if flowcell in f5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FAK71722': ['DESKTOP_CHF4GRO_20190504_FAK71722_MN21390_sequencing_run_05_04_19_run_02_87174.fast5', 'DESKTOP_CHF4GRO_20190504_FAK71722_MN21390_sequencing_run_05_04_19_run02_f.fast5', 'DESKTOP_CHF4GRO_20190504_FAK71722_MN21390_sequencing_run_05_04_19_run02_e.fast5', 'DESKTOP_CHF4GRO_20190504_FAK71722_MN21390_sequencing_run_05_04_19_run02_d.fast5', 'DESKTOP_CHF4GRO_20190504_FAK71722_MN21390_sequencing_run_05_04_19_run02_c.fast5', 'DESKTOP_CHF4GRO_20190504_FAK71722_MN21390_sequencing_run_05_04_19_run02_b.fast5', 'DESKTOP_CHF4GRO_20190504_FAK71722_MN21390_sequencing_run_05_04_19_run02_a.fast5'], 'FAK67809': ['DESKTOP_CHF4GRO_20190504_FAK67809_MN25769_sequencing_run_05_04_19_run_01_40148.fast5', 'DESKTOP_CHF4GRO_20190504_FAK67809_MN25769_sequencing_run_05_04_19_run01_a.fast5', 'DESKTOP_CHF4GRO_20190504_FAK67809_MN25769_sequencing_run_05_04_19_run01_b.fast5', 'DESKTOP_CHF4GRO_20190504_FAK67809_MN25769_sequencing_run_05_04_19_run01_c.fast5', 'DESKTOP_CHF4GRO_20190504_FAK67809_MN25769_sequencing_run_05_04_19_run01_d.fast5', 'DESKTOP_CHF4GRO_20190504_FAK67809_MN25769_sequencing_run_05_04_19_run01_e.fast5', 'DESKTOP_CHF4GRO_20190504_FAK67809_MN25769_sequencing_run_05_04_19_run01_f.fast5']}\n"
     ]
    }
   ],
   "source": [
    "print f5_files_by_flowcell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prefixes_by_flowcell = dict.fromkeys(flowcells)\n",
    "for flowcell in flowcells:\n",
    "    if f5_files_by_flowcell[flowcell]:\n",
    "        prefixes_by_flowcell[flowcell] = re.findall(r\"(.*_)run_\\d+_\\d+.fast5\", f5_files_by_flowcell[flowcell][0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FAK71722': 'DESKTOP_CHF4GRO_20190504_FAK71722_MN21390_sequencing_run_05_04_19_', 'FAK67809': 'DESKTOP_CHF4GRO_20190504_FAK67809_MN25769_sequencing_run_05_04_19_'}\n"
     ]
    }
   ],
   "source": [
    "print prefixes_by_flowcell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate config file(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate config files are generated for runs with separate flow cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:56:01.284873Z",
     "start_time": "2018-09-11T19:56:01.279943Z"
    }
   },
   "outputs": [],
   "source": [
    "config_files_by_flowcell = dict.fromkeys(flowcells)\n",
    "for flowcell in flowcells:\n",
    "    if f5_files_by_flowcell[flowcell]:\n",
    "        config_files_by_flowcell[flowcell] = \"configs/segment_%s_%s.yml\" % (date, flowcell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print example config file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:56:04.513031Z",
     "start_time": "2018-09-11T19:56:04.430938Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast5:\n",
      "  dir: /disk1/pore_data/MinION_raw_data_20190504/\n",
      "  prefix: DESKTOP_CHF4GRO_20190504_FAK67809_MN25769_sequencing_run_05_04_19_\n",
      "  names:\n",
      "    run01: run_01_40148.fast5\n",
      "  run_splits:\n",
      "    run01:\n",
      "    - name: a\n",
      "      start: 0\n",
      "      end: 360\n",
      "    - name: b\n",
      "      start: 420\n",
      "      end: 1140\n",
      "    - name: c\n",
      "      start: 1200\n",
      "      end: 1500\n",
      "    - name: d\n",
      "      start: 1560\n",
      "      end: 2280\n",
      "    - name: e\n",
      "      start: 2340\n",
      "      end: 2640\n",
      "    - name: f\n",
      "      start: 2700\n",
      "      end: 3420\n",
      "segmentation_params:\n",
      "  out_prefix: /disk1/pore_data/segmented/peptides/20190504\n",
      "  min_duration_obs: 10\n",
      "  signal_threshold: 0.7\n",
      "  signal_priors:\n",
      "    prior_open_pore_mean: 220.0\n",
      "    prior_open_pore_std: 35.0\n",
      "fast5:\n",
      "  dir: /disk1/pore_data/MinION_raw_data_20190504/\n",
      "  prefix: DESKTOP_CHF4GRO_20190504_FAK71722_MN21390_sequencing_run_05_04_19_\n",
      "  names:\n",
      "    run02: run_02_87174.fast5\n",
      "  run_splits:\n",
      "    run02:\n",
      "    - name: a\n",
      "      start: 0\n",
      "      end: 300\n",
      "    - name: b\n",
      "      start: 360\n",
      "      end: 1080\n",
      "    - name: c\n",
      "      start: 1140\n",
      "      end: 1440\n",
      "    - name: d\n",
      "      start: 1500\n",
      "      end: 2220\n",
      "    - name: e\n",
      "      start: 2280\n",
      "      end: 2580\n",
      "    - name: f\n",
      "      start: 2640\n",
      "      end: 3360\n",
      "segmentation_params:\n",
      "  out_prefix: /disk1/pore_data/segmented/peptides/20190504\n",
      "  min_duration_obs: 10\n",
      "  signal_threshold: 0.7\n",
      "  signal_priors:\n",
      "    prior_open_pore_mean: 220.0\n",
      "    prior_open_pore_std: 35.0\n"
     ]
    }
   ],
   "source": [
    "for flowcell in flowcells:\n",
    "    if f5_files_by_flowcell[flowcell]:\n",
    "        print \"fast5:\"\n",
    "        print \"  dir: %s/\" % os.path.join(f5_base_dir, f5_dir)\n",
    "        print \"  prefix: %s\" % prefixes_by_flowcell[flowcell]\n",
    "        print \"  names:\"\n",
    "        for run, df in runs_by_date.iteritems(): \n",
    "            if df.iloc[0][\"Flow Cell\"] != flowcell:\n",
    "                continue\n",
    "            run_name = re.findall(r\"run_(\\d+)\", run)[0]\n",
    "            for f5_fname in f5_files_by_flowcell[flowcell]:\n",
    "                try:\n",
    "                    if \"run_%s\" % run_name in re.findall(r\"(run_\\d+_\\d+.fast5)\", f5_fname)[0]:\n",
    "                        r = re.findall(r\"(run_\\d+_\\d+.fast5)\", f5_fname)[0]\n",
    "                        print \"    run%s: %s\" % (run_name, r)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "        print \"  run_splits:\"\n",
    "        formatted_coords = {}\n",
    "        for run, df in runs_by_date.iteritems(): \n",
    "            if df.iloc[0][\"Flow Cell\"] != flowcell:\n",
    "                continue\n",
    "            formatted_coords[run] = [] \n",
    "            r = re.findall(r\"run_(\\d+)\", run)\n",
    "            print \"    run%s:\" % r[0]\n",
    "            mod = 0\n",
    "            for i, coords in enumerate(df.loc[:, [\"start (sec)\", \"end (sec)\"]].iterrows()):\n",
    "                letter = alpha[i - mod]\n",
    "                if np.isnan(coords[1][0]):\n",
    "                    mod += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    start = int(coords[1][0])\n",
    "                if np.isnan(coords[1][1]):\n",
    "                    end = start + 100\n",
    "                else:\n",
    "                    end = int(coords[1][1])\n",
    "                print \"    - name: %s\" % letter\n",
    "                print \"      start: %d\" % start\n",
    "                print \"      end: %d\" % end\n",
    "                formatted_coords[run].append({\"name\": letter, \"start\": start, \"end\": end})\n",
    "        print \"segmentation_params:\"\n",
    "        print \"  out_prefix: /disk1/pore_data/segmented/peptides/%s\" % date\n",
    "        print \"  min_duration_obs:\", min_duration_obs\n",
    "        print \"  signal_threshold:\", signal_threshold\n",
    "        print \"  signal_priors:\"\n",
    "        print \"    prior_open_pore_mean:\", open_pore_mean\n",
    "        print \"    prior_open_pore_std:\", open_pore_stdv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to config file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-08T18:51:20.207533Z",
     "start_time": "2018-09-08T18:51:19.401606Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for flowcell in flowcells:\n",
    "    if f5_files_by_flowcell[flowcell]:\n",
    "        with open(config_files_by_flowcell[flowcell], \"w+\") as f:\n",
    "            f.write(\"fast5:\\n\")\n",
    "            f.write(\"  dir: %s\\n\" % os.path.join(f5_base_dir, f5_dir))\n",
    "            f.write(\"  prefix: %s\\n\" % prefixes_by_flowcell[flowcell])\n",
    "            f.write(\"  names:\\n\")\n",
    "            for run, df in runs_by_date.iteritems():\n",
    "                if df.iloc[0][\"Flow Cell\"] != flowcell:\n",
    "                    continue\n",
    "                run_name = re.findall(r\"run_(\\d+)\", run)[0]\n",
    "                for f5_fname in f5_files_by_flowcell[flowcell]:\n",
    "                    try:\n",
    "                        if \"run_%s\" % run_name in re.findall(r\"(run_\\d+_\\d+.fast5)\", f5_fname)[0]:\n",
    "                            r = re.findall(r\"(run_\\d+_\\d+.fast5)\", f5_fname)[0]\n",
    "                            f.write(\"    run%s: %s\\n\" % (run_name, r))\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "            f.write(\"  run_splits:\\n\")\n",
    "            formatted_coords = {}\n",
    "            for run, df in runs_by_date.iteritems():\n",
    "                if df.iloc[0][\"Flow Cell\"] != flowcell:\n",
    "                    continue\n",
    "                formatted_coords[run] = [] \n",
    "                r = re.findall(r\"run_(\\d+)\", run)\n",
    "                f.write(\"    run%s:\\n\" % r[0])\n",
    "                mod = 0\n",
    "                for i, coords in enumerate(df.loc[:, [\"start (sec)\", \"end (sec)\"]].iterrows()):\n",
    "                    letter = alpha[i - mod]\n",
    "                    if np.isnan(coords[1][0]):\n",
    "                        mod += 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        start = int(coords[1][0])\n",
    "                    if np.isnan(coords[1][1]):\n",
    "                        end = start + 100\n",
    "                    else:\n",
    "                        end = int(coords[1][1])\n",
    "                    f.write(\"    - name: %s\\n\" % letter)\n",
    "                    f.write(\"      start: %d\\n\" % start)\n",
    "                    f.write(\"      end: %d\\n\" % end)\n",
    "                    formatted_coords[run].append({\"name\": letter, \"start\": start, \"end\": end})\n",
    "            f.write(\"segmentation_params:\\n\")\n",
    "            f.write(\"  out_prefix: /disk1/pore_data/segmented/peptides/%s\\n\" % date)\n",
    "            f.write(\"  min_duration_obs: %d\\n\" % min_duration_obs)\n",
    "            f.write(\"  signal_threshold: %f\\n\" % signal_threshold)\n",
    "            f.write(\"  signal_priors:\\n\")\n",
    "            f.write(\"    prior_open_pore_mean: %f\\n\" % open_pore_mean)\n",
    "            f.write(\"    prior_open_pore_std: %f\\n\" % open_pore_stdv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate ipython notebook(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate ipython notebooks are generated for runs with separate flowcells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-08T17:33:48.953282Z",
     "start_time": "2018-09-08T17:33:48.887452Z"
    }
   },
   "outputs": [],
   "source": [
    "for flowcell in flowcells:\n",
    "    if f5_files_by_flowcell[flowcell]:\n",
    "        template_fname = \"experiment_TEMPLATE.ipynb\"\n",
    "        notebook_fname = \"experiment_%s_%s.ipynb\" % (date, flowcell)\n",
    "        with open(template_fname, \"r\") as template_nb:\n",
    "            lines = template_nb.readlines()\n",
    "            lines = \"\\n\".join(lines)\n",
    "            lines = lines.replace(\"INSERT_DATE\", date)\n",
    "            lines = lines.replace(\"INSERT_FLOWCELL\", flowcell)\n",
    "        with open(notebook_fname, \"w+\") as nb:\n",
    "            nb.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
